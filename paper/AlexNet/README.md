# AlexNet

## [ImageNet Classification with Deep Convolutional Neural Networks](https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)

#### AlexNet code 구현

## Abstract

#### ImageNet LSVRC-2010 contest 에서 1200만개의 고해상도 이미지를 분류하기 위하여 CNN모델을 학습시켰다.
#### Test 데이터에서 top-1 and top-5 error rate를 37.5%, 17%로 이전기술보다 개선되었다.
#### 6000만개의 파라미터와 65만개의 뉴런으로 구성되었고, 몇개의 max-pooling layer를 포함한 5개의 CNN layer, 3개의 Fully-connected layer로 구성되었고 마지막층은 softmax 함수가 있다.
#### 빠른 train을 위하여 non-saturaing(발산함수 ex. relu) 뉴런을 사용하였고, CNN연산을 위한 효과적인 GPU 구현했다.
#### Overfitting을 줄이기 위해, Dropout 을 적용했다.
#### 위 모델의 변형으로 ImageNet LSVRC-2012 에서 또한 top-5 error rate를 15.3%를 달성하였으며, 2등의 26.2%와 많은 격차를 냈다.

## 1. Introduction
#### 현재 객체인식의 접근법에는 머신러닝 필수적으로 사용된다. 성능을 개선하기위하여 우리는 많은 데이터셋을 모으고, 강한 모델을 학습하고, 오버피팅을 방지하기위해 더 나은 기술을 적용한다.
#### 최근까지 라벨링된 데이터는 상대적으로 적었다. 작은 객체인지는 특히 데이터 증강이 이루어진 이후에 대해서 작은 데이터셋에서도 잘 이루어졌다.
#### 현실의 데이터는 매우 다양하기 때문에, 이를 학습하기 위해서는 거대한 학습데이터가 필요하다.
#### 실제로 소규모 데이터 셋의 단점은 널리 알려져 있다. 그러나 이제는 LabelMe, ImageNet과 같은 수많은 레이블된 데이터를 얻을 수 있다. 
#### 몇만개의 이미지중에서 몇천개의 객체를 학습하기 위해서는 거대한 용량의 모델이 필요하다.
#### 그러나 객체인식의 복잡성은 ImageNet 만큼 거대한 데이터셋으로도 해결하지 못할만큼 어렵다는 것을 의미합니다. 그래서 우리의 모델은 우리가 몰랐던 모든 사전지식을 적용해 보강해야했다.
#### CNN 모델은 깊이와 너비를 다양하게 조절할 수 있고, 좋은 정확도를 나타낸다. 게다가 비슷한 사이즈의 기존 신경망에 비해 적은 연결과 파라미터로 쉽게 훈련이 가능했다.
#### 운이좋게도 현재의 GPU의 성능과 잘 최적화된 2D Convolution으로 거대 CNN 을 학습시키기엔 충분했다.
#### 논문의 성과 : <br> 1. ILSVRC-2010 and ILSVRC-2012 에서 거대 CNN 모델을 학습시켜 좋은 성적을 달성했다. <br> 2. 2D Convolution 에 최적화된 GPU 구현으로 공식적으로 사용이 가능함을 증명했다. <br> 3. 성능을 향상시키고 시간을 단축시키는 방법. <br> 4. 오버피팅을 방지하기 위한 효과적인 기술을 사용했다. <br> 5. 5개의 CNN 레이어와 3개의 Fully-connected 레이어로 구성하였는데, 깊이가 매우 중요했다. 하나의 Convolution layer를 지워보았는데 성능의 저하가 발생했다.
#### 네트워크 크기의 제한은 현재 GPU의 메모리에의해 제한되며, 더 빠른 GPU와 큰 데이터 셋이 있다면 성능이 향샹 될 것이다.

## 2. The Dataset
#### ImageNet은 22,000개의 카테고리를 가진 1500만개의 고해상도 데이터 셋이다.
#### ILSVRC는 ImageNet의 부분집합을 사용한다. 대략 120만개의 Train data, 5만개의 Validation data, 15만개의 Test data.
#### ImageNet은 다양한 고해상도 이미지로 구성되어있고, 우리는 고정된 차원의 Input이 필요하다. 따라서 256x256 사이즈로 이미지를 다운샘플링했다. 사각형의 이미지가 주어지면, 짧은 부분의 길이가 256이 되도록 다운샘플링 후 중앙에서 256x256이미지를 추출했다.
#### 이미지에서 평균값을 빼는것 말고는 다른 전처리는 수행하지 않았고, RGB값을 가지는 픽셀들로 훈련을 진행했다.

## 3. The Architecture
#### 요약된 구조는 Figure 2. 를 참고하면 된다.
#### 8개의 훈련된 레이어로 구성되어있고, 5개의 Convolution 레이어, 3개의 Fully-connected 레이어로 구성되었다.
#### 중요도에 따라 섹션 3.1~4의 순서대로 정렬했다.

### 3.1 ReLU Nonlinearity
<img width="412" alt="image" src="https://github.com/by-hwa/Docs/assets/102535447/d285d64e-db22-49be-95ca-f3623e5506c5">
Figure1 <br> ReLUs(solid line), tanh(dashed line) <br> CIFAR-10 데이터에 대해 6epoch 만에 error rate 25%를 달성했고, 어떠한 정규화도 사용하지 않았다. <br>ReLU 함수가 수렴함수보다 빠르게 학습하는것을 알 수 있었다.

#### 활성함수로 tanh 함수 또는 Sigmoid 함수를 주로 사용했다. 경사하강법을 사용한 훈련시간 측면에서 이 saturating nonlinearities 함수들이 non-saturating nonlinearities max(0,x) 함수보다 느리다. Nair and Hinton에 의해 non-saturating nonlinearities 함수를 Rectified Linear Units, ReLU 라 명명했다.
#### ReLU가  tanh 함수보다 빠른 학습능력을 보였다. Figure 1.
#### 전통적인 방식을 고려하지 않은 것은 아니다. 예를 들면 avg pooling을 사용한 데이터셋 Caltech-101에서 좋은 성능을 보였다. 그러나, 우리의 목표는 Overfitting을 방지하는 것 이기때문에 Overfitting이 관측되는 효과는 train set을 활동을 가속화 하는 것과 다르다.

### 3.2 Training on Multiple GPUs
#### GTX 580 GPU 는 3GB의 메모리를 가지고 있다. 이는 학습시에 네트워크의 크기를 결정한다. 하나의 GPU로 120만개의 데이터를 학습하기에는 벅찼고 2개의 GPU를 사용하였다.
#### 현재의 GPU는 병렬처리를 하기에 적합하다, GPU간 서로 주메모리에 접근없이 서로 메모리에 접근하고 읽고쓰기가 가능하다. GPU마다 커널(뉴련)의 반을 놓았다.
#### 연결패턴을 선택하는것은 Cross-Validation시에 문제가 되지만, 이것은 계산 양의 비율을 정확하게 조정해준다.
####  "columnar" CNN 아키텍처와 유사하지만, 우리의 아키텍처는 독립적이지 않고 2개의 GPU의 사용으로 에러를 낮췄다.

### 3.3 Local Response Normalization
#### ReLU는 Saturating을 막기위해 정규화를 할 필요가 없다. 그러나 우리는 다음에 나오는 지역 정규화 방법이 일반화를 돕는다는 사실을 발견했다.
#### 특정층에 ReLU를 적용한 후 이 정규화를 적용했다.
#### Jarrett의 지역 대비 정규화와 일부분 닮았지만, 여기에선 평균을 빼지 않기 때문에 '밝기 정규화'라고 부른다. 또 유의미한 에러율의 감소를 보였다.
#### Response Normalize 를 사용하여 top-1, top-5 error를 1.4%, 1.2% 달성했고, CIFAR-10 데이터에 대해 비정교화 13%, 정규화 11%의 에러율을 달성했다.

### 3.4 Overlapping Pooling
#### CNN 의 풀링 레이어는 같은 커널 맵의 이웃 그룹의 출력을 요약한다.
#### 전통적으로, 인접풀링 레이어들에 의해 요약된 이웃들은 중첩되지 않는다.
#### 자세히 말하자면, s 픽셀 단위로 이루어진 풀링 그리드가 중심에서 z x z 크기의 인접뉴런을 요약한다. 만약 s = z 라면 CNN의 전통적인 풀링방식이 된다. 하지만 우리는 s = 2, z = 3 으로 s<z로 설정하여 풀링되는 뉴런들의 중복되게 하였다. 또한 이 방법이 모델이 Overfitting되기 약간 더 어렵다는 것을 알게되었다.

### 3.5 Overall Architecture
<img width="1000" alt="image" src="https://github.com/by-hwa/Docs/assets/102535447/f0c2e722-0f73-4403-ba7b-18b18da54595">
Figure2 <Br> CNN Architecture, 상하단의 레이어를 각각 GPU에 나뉘어 실행한다. GPU는 특정 계층에서만 통신한다. 신경망의 입력은 150, 528차원이고, 나머지 계층에 있는 뉴런의 수는 253,440–86, 624–64,896–64,896–43,264–4096–4096–1000 이다.

#### Figure2 에서 보듯, 가중치를 가진 8개의 레이어로 구성되어 있다. 처음 5개의 레이어는 Convolution이고, 나머지 3개는 Fully-connect 이다. 마지막 레이어의 출력은 1000개의 클래스의 출력에 대한 1000-way softmax으로 제공한다.
#### 우리의 네트워크는 다항 로지스틱 회귀 목표를 최대화 한다. 이는 올바른 레이블 예측분포에서 로그 확율에 대한 학습 케이스의 전체의 평균을 최대화 한것과 같다.
#### 2, 4, 5번째 합성곱 계층의 커널은 오직 같은 GPU에 있는 이전 계층의 커널만 연결된다. 3번째 계층은 모든 2번째 계층과 연결된다. Fully-conntect의 뉴런들 또한 이전의 모든 계층과 연결된다.
#### Response Normalization layer는 첫번째와 두번째 레이어 뒤에 나온다.
#### 3.4에서 설명한 Max pooling layer와 Response normalization layer 다섯번 째 레이어 뒤에 나온다.
#### ReLU는 모든 Convolution 및 Fully-Connect의 출력에 적용된다.
#### 1st Conv layer, 227x227x3의 이미지를 입력받아 stride=4를 적용하여 11x11x3 크기의 커널을 96개의 채널로 출력한다.
#### 2nd Conv layer, layer1의 출력을 입력으로 받아 5x5x48인 커널로 256개의 채널을 출력한다.
#### 3rd, 4th, 5th Conv layer, 풀링 및 정규화 레이어 없이 서로 연결된다.
#### 3rd Conv layer, layer2의 출력을 입력으로 받아 3x3x256인 커널로 384개의 채널을 출력한다.
#### 4th Conv layer, layer3의 출력을 입력으로 받아 3x3x192인 커널로 384개의 채널을 출력한다.
#### 5th Conv layer, layer4의 출력을 입력으로 받아 3x3x192인 커널로 256개의 채널을 출력한다.
#### 각각의 Fully-connect 계층은 4096개의 뉴런으로 이루어져있다.


## 4. Reducing  Overfitting
#### 우리의 신경망은 6천만개의 파라미터가 있습니다. ILSVRC는 각각 훈련된 샘플을 레이블하는데 10비트의 제약이 있었고 Overfitting 없이 파라미터를 학습시기키엔 어려움이 있었다.
#### 아래에서는 우리가 사용한 Overfitting읇 방지하는 두가지 방법을 설명합니다.

### 4.1 Data Augmentation
#### 이미지 데이터에서 Overfitting을 막기 위한 가장 쉬운 방법은 label-perseving 변환을 이용하여 데이터를 증강하는 것이다. 우리는 두가지 방법을 이용하여 데이터 증강을 시켰다. 원본데이터에 약간의 변형을 주어 변환된 이미지를 생성. 이전 배치에서 GPU가 훈련중일때 Python코드를 이용하여 CPU를 이용하여 이미지를 생성하도록 하였다.
#### 1. Image translation and horizontal-reflection이다 256x256이미지에서 랜덤하게 224x224 크기의 데이터를 추출하고 훈련시켰다. 당연하게도 높은 상호 의존성을 보였지만 훈련세트는 2048배 증가하였다. 테스트 시에는 각 모서리 4곳과 가장 중앙의 1곳 horizontal-reflections 까지 합한 총 10개로 증강된 이미지의 예측을 softmax계층에서 평균함으로써 예측한다.
#### 2. 훈련데이터의 RGB채널의 강도를 바꾸어 데이터를 증강한다. 구체적으로, 우리는 훈련세터의 RGB값에 대해 PCA를 수행하고 각 훈련 이미지에, 우리는 평균이 0이고 표준 편차가 0.1인 가우시안값에 비례하는 크기의 랜덤 변수와 이미지에서 발견된 주요 구성요소의 배수를 더한다.
#### Ixy =[IRxy, IGxy, IBxy]T 에 [p1, p2, p3][α1λ1, α2λ2, α3λ3]를 더한다.
####   pi 와 λi 는 i번째 고유벡터와 RGB픽셀의 3X3 공분산 행렬의 고유값이고 αi 는 앞서 언급한 랜덤 변수이다. 각 는 특정 훈련 이미지가 다시 훈련될때 모든 픽셀에 대해 한번만 그려진다. 이 방법은 원본이미지에 대해 대략적으로 중요한 특성을 뽑아내고 조명의 세기와 색상의 변화에 대해 변하지 않는다. 또한 top-1 에러율을 1%넘게 낮춰주었다.

### 4.2 Dropout
#### 서로 다른 모델의 예측 값을 합치는 것은 테스트 에러를 줄이는 좋은 방법이다. 하지만 훈련하는데 수일이 걸리는 큰 신경망에는 적용하기 힘들다. 훈련비용은 2배이지만 효과적으로 모델을 합치는 방법이 있는데 이를 'Dropout'이라고 한다. 이 기술은 각 은닉층의 뉴런들을 0.5프로 확율로 0을 출력하게 한다. 드롭아웃된 뉴런들은 순적파 역전파에 관여하지않는다. 이 기술은 특정 뉴런이 다른 뉴런에 의존할 수 없기 때문에 복잡한 가중치 조절을 감소해준다. 그렇기 때문에 많은 뉴런들의 집합으로 부터 특성을 학습하는데 초점을 맞출 수 있다. 이는 많은 드롭아웃 네트워크에 의해 생성된 예측 분포의 기하학적 평균을 취하는 것에 대한 합리적인 근사치이다.

## 5. Detail of Learning
#### 우리는 batch_size=128, momentum=0.9, weight_decay=0.0005 의 확률적 경사하강법을 이용하였다. 우리는 작은 weight_decay를 사용하는 것이 학습에 중요하다는 것을 깨달았다. 이는 weight_decay가 단순히 규제 작용을 할 뿐만 아니라 모델의 훈련에러도 줄여주었다. 가중치 w에 대해 다음과 같이 업데이트 되는데,
![image](https://github.com/by-hwa/Docs/assets/102535447/a5bed44f-25f9-4ffe-9f09-db308fa0a76e)

#### i = iteration, v = momenterm variable, e = learning rate
![image](https://github.com/by-hwa/Docs/assets/102535447/b4f1cff4-4fef-4daa-9684-8fd6d3878c7c)
는 wi에서 계산된 목적 도함수 w 에 대하여 i번째 배치의 평균인 를 뜻한다.

#### layer에 대해 평균이 0이고 표준편차가 0.01인 가우시안 분포로 가중치를 초기화 했다. 우리는 2,4,5번째 Conv layer과 Fully-Connect의 편향(biases)을 상수 1로 초기화 했다. 이는 ReLU에 양수의 입력을 주어 초기단계의 학습을 가속시켜준다. 나머지 계층의 편향은 모두 0으로 초기화 했다.

#### 모든 계층에서 동일한 학습률을 적용하였고 훈련내내 수동으로 조정하였다. 우리는 검증 에러가 현재 학습률에서 더 나아지지 않을 때 학습률을 10으로 나누는 휴리스틱을 따랐다. 학습률은 0.01로 시작하여 종료되기까지 3회 감소하였다. 우리는 2개의 NVIDIA GTX 580 3GB GPUs 를 이용하여 5~6일에 걸쳐 120만개의 이미지를 90epoch정도 학습시켰다.

## 6. Results
![image](https://github.com/by-hwa/Docs/assets/102535447/b23a9261-b6f5-4be4-9b54-40fe32ad7d55)
<Br>Table 1 <Br> ILSVRC-2010의 결과 이테릭채는 다른팀의 최고점.

![image](https://github.com/by-hwa/Docs/assets/102535447/a07cbe93-2ba4-4e7c-b363-c245b871f9b7)
<Br>Table 2 <Br> ILSVRC-2012의 에러률 검증. 이테륵체는 다른팀의 최고점. * 표시가 있는 모델은 ImageNet2011의 전체 데이터에 대해 사전학습된 모델이다.

#### ILSVRC-2010 의 결과는 Table 1 과 같다.
#### 우리의 신경망은 테스트셋에서 Top-1 37.5%, Top-5 17.0% 의 에러율을 기록하였다. 47.1%, 28.2%를 기록한 팀은 6개의 희소코딩된 모델의 예측을 평균하여 기록을 달성하였고 45.7%, 25.7%의 모델은 2가지 종류의 밀접한 특성을 이용한 Fisher Vectors를 계산하여 2개의 분류기의 예측을 평균하여 기록을 내었다.
#### 우리는 ILSVRC-2012에도 참가하였는데 그에 대한 기록은 Table 2 에 나와있다.
#### ILSVRC-2012의 테스트셋은 라벨링이 되어있지 않아서 우리가 시도한 모든 모델들의 에러율을 기록하지는 못했다. 이 단락의 마지막 부분에서는 val 과 test의 에러율이 0.1%의 차이를 보이므로 둘을 같은 결과로 사용했다. CNN은 top-5 에러율 18.2%를 기록했다. 비슷한 CNN 5개의 예측을 평균한 모델은 16.4%를 기록했다. ImageNet 2011 Fall 데이터를 분류하기 위해 만든, 풀링계층 이후에 6개의 합성곱 계층을 추가한 CNN 모델을 미세조정(fine-tuning) 시켰을 때 16.6% 에러율을 달성했다. 방금 언급한 미세조정한 모델과 CNN5개의 예측을 평균한 모델을 더해 또다시 예측을 평균하였더니 15.3%의 에러율을 기록하였다. 다양한 종류의 밀접한 특성을 이용하여 Fisher Vectors를 계산하여 여러 분류기의 예측을 평균한 모델은 26.2% 에러율을 기록하며 2위를 달성했다.
#### 마지막으로 우리는 10184 클래스, 890만개의 이미지를 가진 ImageNet Fall 2009의 에러율을 발표하겠다. 이 데이터셋에 대해서는 문헌에 따라 데이터의 절반은 훈련에, 절반은 테스트에 사용했다. 공식적인 테스트셋이 없기 때문에 이전 저자들이 사용한 데이터셋과 다르지만 결과에 미치는 영향은 없다. 우리는 위에서 언급한 풀링계층 이후에 6개의 추가적인 합성곱 계층을 이은 모델로 Top-1 67.4%, Top-5 40.9% 에러율을 기록하며, 기존 78.1%, 60.9%의 기록보다 나은 결과를 보였다.

![image](https://github.com/by-hwa/Docs/assets/102535447/f2ebcab2-f6e6-4610-a205-ea72668203fd)
<Br> Figure3 <Br> 224x224x3 의 입력 이미지를 11x11x3의 96개의 채널 사이즈로 통과시킨 모습. 위의 절반은 GPU1, 아래의 절반은 GPU 2

###  6.1 Qualitative Evaluations
![image](https://github.com/by-hwa/Docs/assets/102535447/26df771d-3781-4393-a083-b02596deec55)
<BR> Figure4 <Br> (왼쪽) 8개의 ILSVRC-2010 테스트 이미지와 모델에서 가장 가능성이 높은 것으로 간주되는 5개의 레이블.
올바른 레이블은 각 이미지 아래에 작성되며 올바른 레이블에 할당된 확률도 빨간색 막대로 표시됩니다(상위 5개에 속하는 경우).
<Br> (오른쪽) 첫 번째 열에 있는 5개의 ILSVRC-2010 테스트 이미지. 나머지 열은 테스트 이미지의 특징 벡터에서 유클리드 거리가 가장 작은 마지막 숨겨진 레이어에서 특징 벡터를 생성하는 6개의 훈련 이미지를 보여줍니다.

#### 이 network에서는 다양한 주파수, 방향, 색상들을 학습했다. 섹션 3.5에서 언급한 두개의 GPU간의 제한된 연결을 떠올려 보아라. GPU1의 커널은 주로 색깔정보가 없지만 GPU2의 커널은 다양한 색상을 담고있다. 이런 특성은 랜덤한 가중치 초기화와는 무관하게 매 실행마다 발생한다.
#### Figure 4의 왼쪽 판넬은 8개의 테스트 이미지에 대해 신경망이 내놓은 Top-5예측을 평가한 지표이다. 심지어 중앙에서 떨어진, 왼쪽에 있는 진드기 조차도 신경망에서 감지할 수 있었다. 대부분의 Top-5 는 일리있는 예측을 보였다. 예를들어 고양이종에 속하는 다른 것들만이 표범의 하위 라벨들로 예측되었다. 때때로는(grille, cherry) 의도된 초점보다는 애매모호성을 띄기도 한다.
#### 신경망의 시각적인 지식을 확인하는 또다른 방법은 마지막 4096개의 은닉층에서 이미지에 의해 유도된 특성 활성화이다. 만약 두 이미지가 작은 Euclidean separation으로 특성이 활성화 되었다면, 우리는 신경망이 매우 높은 수준으로 그 둘이 비슷하다고 생각한다. Figure4는 이 방법에 따르면 테스트셋의 5개의 이미지와 6개의 훈련이미지가 매우 비슷하다는 것을 보여준다. 픽셀 수준에서 생각하면, 검색된 훈련 이미지는 첫번째 열의 이미지와 L2에서 비슷하지 않다는 것을 알아라. 예를 들어, 개와 코끼리 사진은 다양한 포즈로 검색됐다.
#### 두개의 4096차원에서 실수값 벡터의 유클리드 거리의 유사도를 계산하는 것은 비효율적이지만, 오토인코더를 이용하여 짧은 이진코드로 벡터를 압축하여 훈련하면 효율적일 것이다. 이미지 라벨을 사용하지 않기 때문에 의미상으로 비슷하던 말던 모서리에서의 패턴 유사도를 통해 이미지를 검색하는 경향이 있는 raw 픽셀에 오토인코더를 적용하는 것보다 훨씬 좋은 이미지 검색방법일 것이다.

## 7. Discussion
#### 순전히 지도학습만으로 크고 넓은 CNN이 엄청난 기록을 깨는 성과를 보였다. 하나의 합성곱계층만 제거해도 결과가 나빠지는것 또한 발견했다. 예를 들어, 중간에 하나의 계층만 제거해도 top-1 에러율이 2%가 나빠진다. 그렇기에 깊이 또한 우리의 결과에 매우 중요하다.
#### 라벨이 부착된 데이터의 양을 늘리지 않고 네트워크의 크기를 크게 늘릴 수 있는 충분한 계산 능력을 얻을 수 있을 것으로 예상하더라도 비지도 사전 훈련을 사용하지 않았다. 지금까지 우리의 결과는 네트워크를 더 크게 만들고 더 오래 훈련시킴으로써 개선되었지만 더욱 많은 노력이 필요하다. 궁극적으로 우리는 정적이거나 일시적인 형태에서 매우 많은 정보를 주는 비디오 시퀀스에서 크고 넓은 CNN을 적용하고 싶다.
